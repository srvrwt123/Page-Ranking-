{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from numba import jit\n",
    "class LambdaMART:\n",
    "    def __init__(self, number_trees=5, maximum_depth=3, lr=1.0):# the program may run slow when the number of tree is high.\n",
    "        \n",
    "        \"\"\"\n",
    "        number_trees: we set it to default 5. Larger the number of trees slower is the program.\n",
    "        lr = learning rate by which we train the trees.\n",
    "        maximum_depth = Number of nodes till where we need to train our model.\n",
    "        \n",
    "        \"\"\"\n",
    "        self.number_trees = number_trees\n",
    "        self.maximum_depth = maximum_depth\n",
    "        self.lr = lr\n",
    "        self.ndcg_dict = {}\n",
    "        self.trees = []\n",
    "        self.gamma = np.zeros((number_trees, 2**(maximum_depth + 1) - 1))\n",
    "        \n",
    "        \n",
    "    def __idcg__(self, rank):\n",
    "        rank = np.sort(rank)[::-1]\n",
    "        g = np.arange(1, len(rank)+1)\n",
    "        a = np.dot((2**rank - 1), 1/np.log2(g + 1))\n",
    "        return a\n",
    "        \n",
    "    @jit# Accelerate the runtime of the function\n",
    "    def lambda_calc(self, rank, F, query_id):\n",
    "        log_t = np.argsort(F)[::-1]\n",
    "        log_f = log_t +1\n",
    "        # if query id is not in the dictionary we apply the __idcg__ with the rank as the parameter.\n",
    "        if query_id not in self.ndcg_dict:\n",
    "            idcg_init = self.__idcg__(rank) \n",
    "            \n",
    "            if idcg_init != 0:\n",
    "                ndcg_dl = (2**rank - 1)\n",
    "                ndcg_t = ndcg_dl / idcg_init\n",
    "                \n",
    "            else:\n",
    "                ndcg_t = np.zeros(len(rank))\n",
    "                \n",
    "        else:\n",
    "            ndcg_t = self.ndcg_dict[query_id]\n",
    "                   \n",
    "            self.ndcg_dict[query_id] = ndcg_t\n",
    "        delta_s_min = np.reshape(F, (-1, 1))\n",
    "        matrix_s = delta_s_min - np.reshape(F, (1, -1))\n",
    "        ndcg_matrix1 = np.zeros((len(rank), len(rank)))\n",
    "        \n",
    "        log_ds = np.log2(1+log_f)\n",
    "        structure_log = 1 / log_ds\n",
    "        \n",
    "        \n",
    "        for i in range(len(rank)):\n",
    "            for k in range(i+1, len(rank)):\n",
    "                \n",
    "                if rank[i] != rank[k]: # checks whether rank[i] is eaqual to rank[k].\n",
    "                   \n",
    "                    log_change = np.copy(structure_log)\n",
    "                    log_change[i], log_change[k] = log_change[k], log_change[i]\n",
    "                    \n",
    "                    if rank[i] < rank[k]:\n",
    "                        ndcg_matrix1[k, i] = np.dot(ndcg_t, log_change - structure_log)\n",
    "                    \n",
    "                    else:\n",
    "                         ndcg_matrix1[i, k] = np.dot(ndcg_t, log_change - structure_log)\n",
    "                        \n",
    "        matrix_r = 1 + np.exp(matrix_s)                \n",
    "        div_matrix = 1 / matrix_r\n",
    "        ndcg_matrix_avg = np.abs(ndcg_matrix1)\n",
    "        matrix_r = ndcg_matrix_avg\n",
    "        matrix_o = matrix_r* div_matrix\n",
    "        lambda_M = -matrix_r\n",
    "        a_init = (1 - div_matrix)\n",
    "        matrix_r = matrix_r*a_init \n",
    "        lambda_t = lambda_M.T\n",
    "        lambda_M = lambda_M-lambda_t \n",
    "        t_lambda =  matrix_r.T\n",
    "        matrix_r = matrix_r + t_lambda \n",
    "        matrix_sum1 = np.sum(lambda_M, axis=0), np.sum(matrix_r, axis=0)\n",
    "        return matrix_sum1\n",
    "  \n",
    "   \n",
    "    \n",
    "    def fit(self, X, rank, qid):\n",
    "        # It gathers the prediction through each and every tree processed by the learning rate\n",
    "        #Fit the model on the training data. \n",
    "        F = np.zeros(np.shape(X)[0])\n",
    "        for k in range(self.number_trees):\n",
    "            lambda_array = np.array([])\n",
    "            omega_array = np.array([])\n",
    "            for u_query_id in np.unique(qid):\n",
    "                query_id_lambda, query_id_omega = self.lambda_calc(rank[qid == u_query_id], \n",
    "                                                         F[qid == u_query_id], u_query_id)\n",
    "                lambda_array = np.append(lambda_array, query_id_lambda)\n",
    "                omega_array = np.append(omega_array, query_id_omega)\n",
    "            tree_reg = DecisionTreeRegressor(max_depth=self.maximum_depth)\n",
    "            tree_reg.fit(X, lambda_array)\n",
    "            self.trees.append(tree_reg)\n",
    "            leaves = tree_reg.apply(X)\n",
    "            for branch_id in np.unique(leaves):\n",
    "                branch_id1 = (leaves == branch_id)\n",
    "                self.gamma[k, branch_id] = np.sum(lambda_array[branch_id1]) / (np.sum(omega_array[branch_id1]))\n",
    "                T = self.lr * branch_id1 * self.gamma[k, branch_id]\n",
    "                F = F+T\n",
    "                \n",
    "    def predict(self, X):\n",
    "        # Predicts score for the test dataset\n",
    "        F = np.zeros(np.shape(X)[0])\n",
    "        for k in range(len(self.trees)):\n",
    "            leaves = self.trees[k].apply(X)\n",
    "            for branch_id in np.unique(leaves):\n",
    "                branch_id1 = (leaves == branch_id)\n",
    "                L_id = self.lr * branch_id1 \n",
    "                M_id = L_id* self.gamma[k, branch_id]\n",
    "                F = F + M_id \n",
    "        return F\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating optimization technique - Discounted Cumulative Gain\n",
    "def dcg(t, k):\n",
    "    i = np.arange(1, len(t)+1)\n",
    "    g = (2**t - 1)\n",
    "    g_calc= g/np.log2(i + 1)\n",
    "    if k is not None:\n",
    "        g_calc = g_calc[i <= k]\n",
    "    return g_calc.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating optimization technique - ideal Discounted Cumulative Gain\n",
    "def idcg(t, k):\n",
    "    t = np.sort(t)[::-1]\n",
    "    i = np.arange(1, len(t)+1)\n",
    "    g = (2**t - 1)\n",
    "    g_calc = g/np.log2(i + 1)\n",
    "    if k is not None:\n",
    "        g_calc = g_calc[i <= k]\n",
    "    return g_calc.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating optimization technique - Normalized Discounted Cumulative Gain\n",
    "def ndcg(t, k):\n",
    "    idcg_value = idcg(t, k=k)\n",
    "    if idcg_value == 0:\n",
    "        return 0\n",
    "        \n",
    "    else:\n",
    "        return dcg(t, k=k) / idcg_value  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating optimization technique - Normalized Discounted Cumulative Gain Mean\n",
    "def ndcg_mean(t_calc, k):\n",
    "    ndcg_val = 0\n",
    "    for qid in t_calc['QId'].unique():\n",
    "        t = t_calc[t_calc['QId'] == qid]['t']\n",
    "        ndcg_que = ndcg(t, k=k)\n",
    "        ndcg_val = ndcg_val + ndcg_que\n",
    "    return ndcg_val / t_calc['QId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the training dataset by using load_svmlight_file .\n",
    "# This format has one sample for per line. Features with value zero are not stored here.\n",
    "data_frame, rank, qid = load_svmlight_file('train.txt', query_id = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We load the test dataset by using load_svmlight_file .\n",
    "df_test, rank_test, qid_test = load_svmlight_file('test.txt', query_id = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total queries in the dataset: 6000\n"
     ]
    }
   ],
   "source": [
    "#Total number of queries in the dataset\n",
    "print(f'Total queries in the dataset: {len(np.unique(qid))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we select some random queries from the dataset. This is set to 1000.\n",
    "sample_size = 1000\n",
    "sample_value = random.sample(list(np.unique(qid)), sample_size)\n",
    "sample_query = (qid == sample_value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in sample_value[1:]:\n",
    "    sample_query |= (qid == idx)\n",
    "df_1 = data_frame[sample_query]\n",
    "rank_1 = rank[sample_query]\n",
    "qid_1 = qid[sample_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into test and train where I specified the size (test size) as 0.2, the rest is training that is the remaining 80 percent.\n",
    "train_vid, cumulative_idx = train_test_split(np.unique(qid_1), size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qid1 = (qid_1 == train_vid[0])\n",
    "for idx in train_vid[1:]:\n",
    "    train_qid1 |= (qid_1 == idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cvid1 = (qid_1 == cumulative_idx[0])\n",
    "for idx in cumulative_idx[1:]:\n",
    "    train_cvid1 |= (qid_1 == idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_frame = df_1[train_qid1]\n",
    "train_df_rank = rank_1[train_qid1]\n",
    "query_id_training = qid_1[train_qid1]\n",
    "\n",
    "data_frame_train1 = df_1[train_cvid1]\n",
    "cumulative_rank = rank_1[train_cvid1]\n",
    "queryid_calc = qid_1[train_cvid1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97032"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_rank) # length of the rank by the query if of training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# We then apply the LambdaMart with the deired input arguments\n",
    "model = LambdaMART(number_trees=100, maximum_depth=4, lr=0.125)\n",
    "model.fit(train_data_frame, train_df_rank, query_id_training)# model is then fit into the data frames and the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we predict the model on the traiining set.\n",
    "predictions = model.predict(data_frame_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'negative_value': -predictions, 'QId': queryid_calc, \n",
    "                       'Document_Id': np.arange(1, len(queryid_calc)+1), 't': cumulative_rank})\n",
    "result = result.sort_values(by=['QId', 'negative_value'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3881777197772533"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndcg_mean(result, k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We predict the model for the test set.\n",
    "predictions_model = model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = pd.DataFrame({'negative_value': -predictions_model, 'QId': qid_test, 'Document_Id': np.arange(1, len(qid_test)+1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = result1.sort_values(by=['QId', 'negative_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The result is printed to the csv file named ranking.csv.\n",
    "result1[['QId', 'Document_Id']].to_csv('ranking.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
